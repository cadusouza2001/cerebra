# 1. Cerebra üß†

## 1.1. Vis√£o Geral do Projeto

O **Cerebra** √© um sistema simples de Perguntas e Respostas (Q&A) constru√≠do em Python. Ele transforma uma cole√ß√£o de p√°ginas da web em um especialista capaz de responder a quest√µes sobre aquele conte√∫do. Todo o modelo √© treinado do zero utilizando PyTorch e dados gerados automaticamente com a API Gemini.

## 1.2. Descri√ß√£o do Problema e Justificativa

Sistemas de Perguntas e Respostas (Q&A) s√£o cada vez mais utilizados em aplica√ß√µes que exigem consulta a documenta√ß√µes t√©cnicas, como bases de conhecimento, manuais ou APIs. No entanto, esses sistemas frequentemente exigem treinamento caro ou n√£o s√£o adapt√°veis a dom√≠nios espec√≠ficos.

Este projeto prop√µe uma solu√ß√£o que transforma automaticamente uma documenta√ß√£o t√©cnica (neste caso, a do Apache Spark) em um modelo especialista capaz de responder perguntas com base no conte√∫do. O sistema utiliza redes neurais para entender linguagem natural, sendo √∫til em contextos educacionais, t√©cnicos e corporativos.

**Justificativa do uso de redes neurais:**  
Redes neurais oferecem flexibilidade para capturar padr√µes lingu√≠sticos e gerar respostas coesas. O modelo foi treinado do zero, refor√ßando os conceitos da disciplina e permitindo controle total da arquitetura.

## 1.3. Sobre o Dataset

O conjunto de dados foi gerado automaticamente a partir da documenta√ß√£o do Apache Spark usando a API Gemini. Cada entrada √© composta por uma **pergunta gerada automaticamente** e uma **resposta contextualizada**, com base em trechos extra√≠dos da documenta√ß√£o oficial.

- **Formato:** JSONL com pares `{"question": ..., "answer": ...}`
- **Tamanho aproximado:** 12.000 pares
- **Pr√©-processamento:** chunking com sobreposi√ß√£o de texto e verifica√ß√£o de coer√™ncia da resposta com o trecho original
- **Local:** `qa_dataset/spark_qa_generative_dataset.jsonl`

> O processo de gera√ß√£o e valida√ß√£o do dataset est√° descrito no script `generate_qa_dataset.py`.

## 1.4. Arquitetura do Modelo

A rede neural utilizada para gera√ß√£o de respostas √© um modelo **seq2seq** (codificador-decodificador) treinado com PyTorch. O modelo foi criado do zero no script `qa_model.py` e treinado com o script `train.py`.
Como o volume de dados √© limitado, tamb√©m disponibilizamos um exemplo de **fine-tuning** de um modelo pr√©-treinado (`t5-small`) no script `fine_tune_t5.py`.
Essa abordagem reutiliza o conhecimento de um modelo grande e reduz o tempo de treinamento.

- **N√∫mero de camadas:** 2 camadas LSTM (encoder e decoder)
- **Fun√ß√£o de ativa√ß√£o:** tanh (impl√≠cita nas c√©lulas LSTM)
- **Embedding:** matriz de embedding trein√°vel (n√£o pr√©-treinada)
- **Perda utilizada:** CrossEntropyLoss
- **Otimiza√ß√£o:** Adam

O foco est√° no **componente Reader**, respons√°vel por formular a resposta com base na pergunta, enquanto a busca de documentos relevantes √© feita pelo `txtai` (Retriever).

### 1.4.1. Tecnologias e bibliotecas

- Python 3.9+
- `aiohttp` e `BeautifulSoup4` para raspagem
- `txtai` para busca por similaridade (Retriever)
- `torch` para treinar a rede neural
- `google-generativeai` para criar pares de pergunta e resposta

## 1.5. Indexa√ß√£o e Recupera√ß√£o

O script `index_spark_docs.py` converte cada p√°gina da documenta√ß√£o em um vetor
sem√¢ntico usando `txtai`. O √≠ndice resultante √© salvo em `spark_docs.index` e,
com a op√ß√£o `content=True`, o texto original fica acess√≠vel para buscas.
Durante a infer√™ncia, `run_qa_system.py` carrega esse √≠ndice e utiliza os
trechos recuperados como contexto para o modelo.

### 1.6. Fazendo Perguntas

Com o √≠ndice criado e o modelo treinado, √© poss√≠vel fazer perguntas via linha de
comando passando a quest√£o diretamente para `run_qa_system.py`:

```bash
python src/run_qa_system.py "What is Apache Spark?"
```

# 2. Execu√ß√£o no Google Colab

Abra o notebook [cerebra_pipeline.ipynb](./cerebra_pipeline.ipynb) no Colab e execute as c√©lulas em ordem. Ele cont√©m todos os comandos necess√°rios para instalar depend√™ncias, configurar as vari√°veis de ambiente, raspar a documenta√ß√£o, treinar o modelo e realizar as avalia√ß√µes.
