# 1. Cerebra üß†

## 1.1. Vis√£o Geral do Projeto

O **Cerebra** √© um sistema simples de Perguntas e Respostas (Q&A) constru√≠do em Python. Ele transforma uma cole√ß√£o de p√°ginas da web em um especialista capaz de responder a quest√µes sobre aquele conte√∫do. Todo o modelo √© treinado do zero utilizando PyTorch e dados gerados automaticamente com a API Gemini.

## 1.2. Descri√ß√£o do Problema e Justificativa

Sistemas de Perguntas e Respostas (Q&A) s√£o cada vez mais utilizados em aplica√ß√µes que exigem consulta a documenta√ß√µes t√©cnicas, como bases de conhecimento, manuais ou APIs. No entanto, esses sistemas frequentemente exigem treinamento caro ou n√£o s√£o adapt√°veis a dom√≠nios espec√≠ficos.

Este projeto prop√µe uma solu√ß√£o que transforma automaticamente uma documenta√ß√£o t√©cnica (neste caso, a do Apache Spark) em um modelo especialista capaz de responder perguntas com base no conte√∫do. O sistema utiliza redes neurais para entender linguagem natural, sendo √∫til em contextos educacionais, t√©cnicos e corporativos.

**Justificativa do uso de redes neurais:**  
Redes neurais oferecem flexibilidade para capturar padr√µes lingu√≠sticos e gerar respostas coesas. O modelo foi treinado do zero, refor√ßando os conceitos da disciplina e permitindo controle total da arquitetura.

## 1.3. Sobre o Dataset

O conjunto de dados foi gerado automaticamente a partir da documenta√ß√£o do Apache Spark usando a API Gemini. Cada entrada √© composta por uma **pergunta gerada automaticamente** e uma **resposta contextualizada**, com base em trechos extra√≠dos da documenta√ß√£o oficial.

- **Formato:** JSONL com pares `{"question": ..., "answer": ...}`
- **Tamanho aproximado:** 12.000 pares
- **Pr√©-processamento:** chunking com sobreposi√ß√£o de texto e verifica√ß√£o de coer√™ncia da resposta com o trecho original
- **Local:** `qa_dataset/spark_qa_generative_dataset.jsonl`

> O processo de gera√ß√£o e valida√ß√£o do dataset est√° descrito no script `generate_qa_dataset.py`.

## 1.4. Arquitetura do Modelo

A rede neural utilizada para gera√ß√£o de respostas √© um modelo **seq2seq** (codificador-decodificador) treinado com PyTorch. O modelo foi criado do zero no script `qa_model.py` e treinado com o script `train.py`.

- **N√∫mero de camadas:** 2 camadas LSTM (encoder e decoder)
- **Fun√ß√£o de ativa√ß√£o:** tanh (impl√≠cita nas c√©lulas LSTM)
- **Embedding:** matriz de embedding trein√°vel (n√£o pr√©-treinada)
- **Perda utilizada:** CrossEntropyLoss
- **Otimiza√ß√£o:** Adam

O foco est√° no **componente Reader**, respons√°vel por formular a resposta com base na pergunta, enquanto a busca de documentos relevantes √© feita pelo `txtai` (Retriever).

### 1.4.1. Tecnologias e bibliotecas

- Python 3.9+
- `aiohttp` e `BeautifulSoup4` para raspagem
- `txtai` para busca por similaridade (Retriever)
- `torch` para treinar a rede neural
- `google-generativeai` para criar pares de pergunta e resposta

## 1.5. Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ qa_dataset/                    # Arquivos de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ spark_qa_generative_dataset.jsonl
‚îú‚îÄ‚îÄ spark_docs_scrape/             # Dados raspados da documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ spark_guides_dataset_clean.jsonl
‚îÇ   ‚îú‚îÄ‚îÄ visited_urls_clean.log
‚îÇ   ‚îî‚îÄ‚îÄ visited_urls_guides.log
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ demo.py                   # Exemplo r√°pido de uso
    ‚îú‚îÄ‚îÄ evaluate_model.py         # Avalia√ß√£o qualitativa
    ‚îú‚îÄ‚îÄ generate_qa_dataset.py    # Cria o dataset com a API Gemini
    ‚îú‚îÄ‚îÄ index_spark_docs.py       # Gera o √≠ndice sem√¢ntico
    ‚îú‚îÄ‚îÄ qa_model.py               # Modelo seq2seq em PyTorch
    ‚îú‚îÄ‚îÄ run_qa_system.py          # Perguntas para o modelo treinado
    ‚îú‚îÄ‚îÄ scrape_fast_resumable.py  # Raspagem ass√≠ncrona da documenta√ß√£o
    ‚îî‚îÄ‚îÄ train.py                  # Treino do modelo do zero
```

# 2. Execu√ß√£o no Google Colab

1. **Prepara√ß√£o do ambiente**

   - Abra um novo notebook no Google Colab e ative o modo **GPU** em `Runtime > Change runtime type`.
   - Clone este reposit√≥rio:
     ```python
     !git clone https://github.com/cadusouza2001/cerebra.git
     %cd cerebra
     ```
   - Instale as depend√™ncias:
     ```python
     !pip install aiohttp beautifulsoup4 txtai torch google-generativeai
     ```
   - (Opcional) Monte o Google Drive para salvar outputs:

     ```python
     from google.colab import drive
     drive.mount('/content/drive')
     ```

2. **Vari√°veis de ambiente**

   - Use o recurso **Secrets** do Colab (√≠cone de chave na lateral):
   - Adicione a vari√°vel `GOOGLE_API_KEY` via interface.
   - No c√≥digo Colab, recupere com:

     ```python
        from google.colab import userdata
        import os
        from google.colab.userdata import SecretNotFoundError

        # Lista de nomes poss√≠veis de segredos
        possible_keys = ["GOOGLE_API_KEY"] + [f"GOOGLE_API_KEY_{i}" for i in range(1, 10)]

        # Verifica e coleta apenas as chaves que est√£o realmente definidas
        api_keys = []
        for k in possible_keys:
            try:
                value = userdata.get(k)
                if value:
                    api_keys.append(value)
            except SecretNotFoundError:
                continue

        if not api_keys:
            raise RuntimeError("Nenhuma chave de API encontrada. Defina pelo menos GOOGLE_API_KEY nos secrets do Colab.")

        # Define a vari√°vel de ambiente esperada pelo seu script
        os.environ["GEMINI_API_KEYS"] = ",".join(api_keys)
     ```

   - Isso garante que a chave √© mantida privada e n√£o inserida diretamente no c√≥digo.
   - Outras vari√°veis podem ser configuradas da mesma forma, por exemplo:
     ```python
     os.environ["DATASET_FILE"] = "qa_dataset/spark_qa_generative_dataset.jsonl"
     os.environ["OUTPUT_MODEL_DIR"] = "spark_expert_model"
     ```

3. **Passo a passo**
   Execute os scripts na ordem abaixo, cada um em uma c√©lula do Colab:
   1. Raspagem da documenta√ß√£o
      ```python
      !python src/scrape_fast_resumable.py
      ```
   2. Cria√ß√£o do √≠ndice sem√¢ntico
      ```python
      !python src/index_spark_docs.py
      ```
   3. Gera√ß√£o autom√°tica do conjunto de dados
      ```python
      !python src/generate_qa_dataset.py
      ```
   4. Treinamento do modelo (usa GPU se dispon√≠vel)
      ```python
      !python src/train.py
      ```
   5. Avalia√ß√£o r√°pida
      ```python
      !python src/evaluate_model.py
      ```
   6. Gera√ß√£o de gr√°ficos e an√°lises
      ```python
      !python src/plot_graphs.py
      ```
   7. Perguntas interativas
      ```python
      !python src/run_qa_system.py
      ```

Os arquivos resultantes s√£o gravados dentro do pr√≥prio diret√≥rio do projeto. O √≠ndice fica em `spark_docs.index` e o modelo treinado em `spark_expert_model/model.pt`.
